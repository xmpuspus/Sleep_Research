{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of features from physiologic signals in polysomnograph data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database source: \n",
    "    \n",
    "    Goldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh, Mark RG, Mietus JE, Moody GB, Peng C-K, Stanley HE. PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals. Circulation 101(23):e215-e220 [Circulation Electronic Pages; http://circ.ahajournals.org/content/101/23/e215.full]; 2000 (June 13).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as ss\n",
    "import seaborn as sns\n",
    "from scipy.ndimage import convolve1d\n",
    "from scipy.stats import entropy\n",
    "import itertools\n",
    "import sleep_utils as su\n",
    "\n",
    "import pickle\n",
    "import datetime  \n",
    "import time \n",
    "import wfdb\n",
    "import glob\n",
    "\n",
    "\n",
    "from biosppy.signals import ecg\n",
    "import nolds\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a file from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = '../data/PSG_database/'\n",
    "\n",
    "co2_sig = []\n",
    "ppg_sig = []\n",
    "\n",
    "filenames = []\n",
    "\n",
    "sleep_data_sigs = {}\n",
    "sleep_data_fields = {}\n",
    "\n",
    "data_keys = []\n",
    "for fname in glob.iglob(data_dir + '/*.dat'):#, recursive=True):\n",
    "    # filename manipulation\n",
    "    base = os.path.basename(fname)\n",
    "    key = os.path.splitext(base)[0]\n",
    "    data_keys.append(key)\n",
    "    \n",
    "    # load data\n",
    "    sig, fields=wfdb.rdsamp(data_dir+key)\n",
    "    sleep_data_sigs[key] = sig\n",
    "    sleep_data_fields[key] = fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ann_index = {}\n",
    "ann_labels = {}\n",
    "\n",
    "set_stages = set()\n",
    "for key in data_keys:\n",
    "    annotation = wfdb.rdann(data_dir + key, 'st')\n",
    "    ann_index_sig = annotation[0]\n",
    "    ann_label_sig = annotation[5]\n",
    "    label_filt = [(x, y) for x, y in zip(ann_index_sig, ann_label_sig) if x >1 ]\n",
    "    unzipped = zip(*label_filt)\n",
    "    ann_index[key] = unzipped[0]\n",
    "    ann_labels[key] = unzipped[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resp_data_set = {}\n",
    "ecg_data_set = {}\n",
    "bp_data_set = {}\n",
    "time_data_set = {}\n",
    "annot_data_set = {}\n",
    "\n",
    "\n",
    "fs = 250\n",
    "dec_prec = len(str(1/fs).split('.')[1])\n",
    "\n",
    "for key in data_keys:\n",
    "    \n",
    "    resp_data_set[key] = (sleep_data_sigs[key])[:, (sleep_data_fields[key])['signame'].index('Resp')]\n",
    "    ecg_data_set[key] = (sleep_data_sigs[key])[:, (sleep_data_fields[key])['signame'].index('ECG')]\n",
    "    bp_data_set[key] = (sleep_data_sigs[key])[:, (sleep_data_fields[key])['signame'].index('BP')]\n",
    "    time_data_set[key] = np.arange(0, len(resp_data_set[key]))/fs\n",
    "\n",
    "    # Note: Only the first character of the annotation was taken as label\n",
    "    # Example: 1, 2, 3, 4, R, W, M\n",
    "    stages_list = [x.rsplit(' ')[0][0] for x in ann_labels[key]]\n",
    "\n",
    "    annot_data_set[key] = stages_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_dir = data_dir + \"PSG_features/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pickle.dump( resp_data_set, open( features_dir + \"resp_data_set.pkl\", \"wb\" ))\n",
    "# pickle.dump( ecg_data_set, open( features_dir + \"ecg_data_set.pkl\", \"wb\" ))\n",
    "# pickle.dump( bp_data_set, open( features_dir + \"bp_data_set.pkl\", \"wb\" ))\n",
    "# pickle.dump( time_data_set, open( features_dir + \"time_data_set.pkl\", \"wb\" ))\n",
    "# pickle.dump( annot_data_set, open( features_dir + \"annot_data_set.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Annotations*\n",
    "\n",
    "Stages:\n",
    "   * W: subject is awake\n",
    "   * 1: sleep stage 1\n",
    "   * 2: sleep stage 2\n",
    "   * 3: sleep stage 3\n",
    "   * 4: sleep stage 4\n",
    "   * R: REM sleep\n",
    "   \n",
    "Other descriptions:\n",
    "   * H: Hypopnea\n",
    "   * HA: Hypopnea with arousal\n",
    "   * OA: Obstructive apnea\n",
    "   * X: Obstructive apnea with arousal\n",
    "   * CA: Central apnea\n",
    "   * CAA: Central apnea with arousal\n",
    "   * L: Leg movements\n",
    "   * LA: Leg movements with arousal\n",
    "   * A: Unspecified arousal\n",
    "   * MT: Movement time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Previous sleep stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Get features for every window of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "win_dur = 30 # duration of window, unit: seconds, size of one epoch \n",
    "win_size = fs*win_dur # length of window\n",
    "win_step = 1 # duration by which the window slides, unit: seconds\n",
    "win_int = win_step*fs # length by which the window slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_prev_stage = {}\n",
    "feature_prev_stage_light = {}\n",
    "feature_prev_stage_deep = {}\n",
    "feature_prev_stage_rem = {}\n",
    "feature_prev_stage_wake = {}\n",
    "feature_prev_stage_move = {}\n",
    "\n",
    "for key in data_keys:\n",
    "    previous = annot_data_set[key][1:]\n",
    "    prev_stage = [np.nan] + previous\n",
    "    feature_prev_stage[key] = {'_feat' : prev_stage}\n",
    "    \n",
    "    # NREM-light or not\n",
    "    feature_prev_stage_light[key] = {'_feat' : [np.nan] +map(lambda x: 0 if x not in ['1', '2'] else 1, previous)}\n",
    "    \n",
    "    # NREM-deep or not\n",
    "    feature_prev_stage_deep[key] = {'_feat' : [np.nan] +map(lambda x: 0 if x not in ['1', '2'] else 1, previous)}\n",
    "    \n",
    "    # REM or not\n",
    "    feature_prev_stage_rem[key] = {'_feat' : [np.nan] + map(lambda x: 0 if x!= 'R' else 1,previous)}\n",
    "    \n",
    "    # Wake or not\n",
    "    feature_prev_stage_wake[key] = {'_feat' :[np.nan] + map(lambda x: 0 if x!= 'W' else 1,previous)}\n",
    "    \n",
    "    # Wake or not\n",
    "    feature_prev_stage_move[key] = {'_feat' :[np.nan] + map(lambda x: 0 if x!= 'M' else 1,previous)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle.dump( feature_prev_stage, open( features_dir + \"feature_prev_stage.pkl\", \"wb\" ))\n",
    "# pickle.dump( feature_prev_stage_light, open( features_dir + \"feature_prev_stage_light.pkl\", \"wb\" ))\n",
    "# pickle.dump( feature_prev_stage_deep, open( features_dir + \"feature_prev_stage_deep.pkl\", \"wb\" ))\n",
    "# pickle.dump( feature_prev_stage_rem, open( features_dir + \"feature_prev_stage_rem.pkl\", \"wb\" ))\n",
    "# pickle.dump( feature_prev_stage_wake, open( features_dir + \"feature_prev_stage_wake.pkl\", \"wb\" ))\n",
    "# pickle.dump( feature_prev_stage_move, open( features_dir + \"feature_prev_stage_move.pkl\", \"wb\" ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Respiration signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Respiratory frequency range \n",
    "min_normrange = 4/60 # unit: cycles per second\n",
    "max_normrange = 65/60 # unit: cycles per second\n",
    "\n",
    "resp_data_set_epochs = {}\n",
    "\n",
    "# Divide ECG data per 30-second epoch. \n",
    "\n",
    "for key in data_keys:\n",
    "    resp_sig = resp_data_set[key]\n",
    "    fft_resp = np.fft.fft(resp_sig)\n",
    "    fft_freqs = np.fft.fftfreq(len(resp_sig), 1/fs)\n",
    "    \n",
    "    # Remove frequencies which are outside the expected range\n",
    "    fft_resp[abs(fft_freqs) < min_normrange] = 0\n",
    "    fft_resp[abs(fft_freqs) > max_normrange] = 0\n",
    "    \n",
    "    resp_filt_sig = np.real(np.fft.ifft(fft_resp))\n",
    "    time_sig = np.arange(len(resp_sig))/fs\n",
    "\n",
    "    # Divide into windows\n",
    "    resp_windows = su.divide_to_epochs(resp_filt_sig, ann_index[key], win_dur, fs)\n",
    "    time_windows = su.divide_to_epochs(time_sig, ann_index[key], win_dur, fs)\n",
    "    \n",
    "    resp_data_set_epochs[key] = pd.DataFrame({'resp': list(resp_windows), '_time': list(time_windows)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.1 Respiration rate\n",
    "*Frequency corresponding to the highest peak in the epoch's power spectrum (unit: breaths/minute)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_resp_rate = {}\n",
    "# feature_resp_rate_fd = {}\n",
    "# feature_resp_rate_sd = {}\n",
    "\n",
    "for key in data_keys:\n",
    "    resp_data = resp_data_set_epochs[key]\n",
    "    resp_data['power_spectrum'] = resp_data.resp.apply(lambda x: ss.periodogram(x, fs=fs))\n",
    "    \n",
    "    # Compute respiration rate\n",
    "    resp_data['resp_rate'] = resp_data.power_spectrum.apply(lambda x: (x[0])[np.argmax(x[1])]*60)\n",
    "\n",
    "    feature_resp_rate[key] = {'_feat' : resp_data.resp_rate.values}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pickle.dump( feature_resp_rate, open( features_dir + \"feature_resp_rate.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.2 Histogram of Respiration data\n",
    "Use the counts for each bin of the magnitude histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nbins = 5\n",
    "\n",
    "feature_hist_resp = {}\n",
    "\n",
    "for key in data_keys:\n",
    "#     print(\"Computing for \"+ key + \"...\")\n",
    "    resp_data = resp_data_set_epochs[key]\n",
    "\n",
    "    hist_windows = resp_data.resp.apply(lambda x: np.histogram(x, bins=nbins, normed=True)[0])\n",
    "    feature_hist_resp[key] = {'_feat' : (np.asarray(hist_windows))}\n",
    "    \n",
    "pickle.dump( feature_hist_resp, open( features_dir + \"feature_hist_resp.pkl\", \"wb\" ))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "#### II.3 Ratio of standard deviation and mean of magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_mean_vs_std_resp = {}\n",
    "\n",
    "for key in data_keys:\n",
    "#     print(\"Computing for \"+ key + \"...\")\n",
    "    resp_data = resp_data_set_epochs[key]\n",
    "\n",
    "    mean_vs_std = resp_data.resp.apply(lambda x: (np.mean(x)/np.std(x)))\n",
    "    feature_mean_vs_std_resp[key] = {'_feat' : list(mean_vs_std)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.4 Ratio of  mean and standard deviation  of peak-to-peak duration of respiration signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for slp01a...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "peakdetect.py:200: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  for index, (x, y) in enumerate(zip(x_axis[:-lookahead],\n",
      "peakdetect.py:201: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  y_axis[:-lookahead])):\n",
      "peakdetect.py:213: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  if y_axis[index:index+lookahead].max() < mx:\n",
      "peakdetect.py:231: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  if y_axis[index:index+lookahead].min() > mn:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for slp01b...\n",
      "Computing for slp02a...\n",
      "Computing for slp02b...\n",
      "Computing for slp03...\n",
      "Computing for slp04...\n",
      "Computing for slp14...\n",
      "Computing for slp16...\n",
      "Computing for slp32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eventura/anaconda/lib/python2.7/site-packages/numpy/lib/nanfunctions.py:675: RuntimeWarning: Mean of empty slice\n",
      "  warnings.warn(\"Mean of empty slice\", RuntimeWarning)\n",
      "/Users/eventura/anaconda/lib/python2.7/site-packages/numpy/lib/nanfunctions.py:1147: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  warnings.warn(\"Degrees of freedom <= 0 for slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for slp37...\n",
      "Computing for slp41...\n",
      "Computing for slp45...\n",
      "Computing for slp48...\n",
      "Computing for slp59...\n",
      "Computing for slp60...\n",
      "Computing for slp61...\n",
      "Computing for slp66...\n",
      "Computing for slp67x...\n"
     ]
    }
   ],
   "source": [
    "feature_mean_vs_std_p2p_dur_resp = {}\n",
    "# feature_max_vs_std_p2p_dur_resp = {}\n",
    "# feature_min_vs_std_p2p_dur_resp = {}\n",
    "\n",
    "for key in data_keys:\n",
    "    print(\"Computing for \"+ key + \"...\")\n",
    "    resp_data = resp_data_set_epochs[key]\n",
    "\n",
    "    p2p_dur = resp_data.resp.apply(lambda x: su.bio_signal_peak_detect(x, fs, 'resp'))\\\n",
    "                            .apply(lambda x: np.array(x[0][1:]) - np.array(x[0][:-1]))\n",
    "    mean_vs_std = p2p_dur.apply(lambda x: np.nanmean(x)/np.nanstd(x))\n",
    "    feature_mean_vs_std_p2p_dur_resp[key] = {'_feat' : list(mean_vs_std)}           \n",
    "    \n",
    "#### II.5 Ratio of max and mean of magnitude of peak-to-peak duration\n",
    "#### II.6 Ratio of min and mean of magnitude of peak-to-peak duration\n",
    "    \n",
    "#     max_vs_std = p2p_dur.apply(lambda x: np.nanmax(x)/np.nanmean(x))\n",
    "#     feature_max_vs_mean_p2p_dur_resp[key] = {'_feat' : list(max_vs_std)}           \n",
    "    \n",
    "#     min_vs_std = p2p_dur.apply(lambda x: np.nanmin(x)/np.nanmean(x))\n",
    "#     feature_min_vs_mean_p2p_dur_resp[key] = {'_feat' : list(min_vs_std)}           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.5 Ratio of mean and standard deviation of amplitude\n",
    "#### II.6 Ratio of max and mean of magnitude of amplitude\n",
    "#### II.7 Ratio of min and mean of magnitude of amplitude\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for slp01a...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "peakdetect.py:200: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  for index, (x, y) in enumerate(zip(x_axis[:-lookahead],\n",
      "peakdetect.py:201: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  y_axis[:-lookahead])):\n",
      "peakdetect.py:213: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  if y_axis[index:index+lookahead].max() < mx:\n",
      "peakdetect.py:231: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  if y_axis[index:index+lookahead].min() > mn:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for slp01b...\n",
      "Computing for slp02a...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-dcba16845468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mresp_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp_data_set_epochs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mamplitude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_amplitude\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'resp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mmean_vs_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamplitude\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mfeature_mean_vs_std_amp_resp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'_feat'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_vs_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eventura/anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2218\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2220\u001b[0;31m             \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:62658)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-dcba16845468>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mresp_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp_data_set_epochs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mamplitude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_amplitude\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'resp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mmean_vs_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamplitude\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mfeature_mean_vs_std_amp_resp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'_feat'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_vs_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eventura/Documents/git-repos/sleep-research/notebooks/sleep_utils.pyc\u001b[0m in \u001b[0;36mcompute_amplitude\u001b[0;34m(sig, fs, sigtype)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_amplitude\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmax_peaks_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_peaks_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_peaks_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_peaks_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbio_signal_peak_detect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_peaks_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmin_peaks_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mmax_peaks_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_peaks_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eventura/Documents/git-repos/sleep-research/notebooks/sleep_utils.pyc\u001b[0m in \u001b[0;36mbio_signal_peak_detect\u001b[0;34m(sig, fs, sigtype)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbio_signal_peak_detect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'resp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0msignaltype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'resp'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ecg'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bp'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mmax_peaks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_peaks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpeakdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookahead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignaltype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msigtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mmax_peaks_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_peaks_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmax_peaks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mmin_peaks_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_peaks_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmin_peaks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eventura/Documents/git-repos/sleep-research/notebooks/peakdetect.pyc\u001b[0m in \u001b[0;36mpeakdetect\u001b[0;34m(y_axis, x_axis, lookahead, delta)\u001b[0m\n\u001b[1;32m    200\u001b[0m     for index, (x, y) in enumerate(zip(x_axis[:-lookahead], \n\u001b[1;32m    201\u001b[0m                                         y_axis[:-lookahead])):\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m             \u001b[0mmx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mmxpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feature_mean_vs_std_amp_resp = {}\n",
    "feature_max_vs_mean_amp_resp = {}\n",
    "feature_min_vs_mean_amp_resp = {}\n",
    "\n",
    "for key in data_keys:\n",
    "    print(\"Computing for \"+ key + \"...\")\n",
    "    resp_data = resp_data_set_epochs[key]\n",
    "\n",
    "    amplitude = resp_data.resp.apply(lambda x: su.compute_amplitude(x, fs, 'resp'))\n",
    "    mean_vs_std = amplitude.apply(lambda x: np.nanmean(x)/np.nanstd(x))\n",
    "    feature_mean_vs_std_amp_resp[key] = {'_feat' : list(mean_vs_std)}           \n",
    "    \n",
    "    max_vs_mean = amplitude.apply(lambda x: np.nanmax(x)/np.nanmean(x))\n",
    "    feature_max_vs_mean_amp_resp[key] = {'_feat' : list(max_vs_mean)}           \n",
    "    \n",
    "    min_vs_mean = amplitude.apply(lambda x: np.nanmax(x)/np.nanmean(x))\n",
    "    feature_min_vs_mean_amp_resp[key] = {'_feat' : list(min_vs_mean)}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.8 Sample entropy of manitude of respiration signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for slp01a...\n",
      "Computing for slp01b...\n",
      "Computing for slp02a...\n",
      "Computing for slp02b...\n",
      "Computing for slp03...\n",
      "Computing for slp04...\n",
      "Computing for slp14...\n",
      "Computing for slp16...\n",
      "Computing for slp32...\n",
      "Computing for slp37...\n",
      "Computing for slp41...\n",
      "Computing for slp45...\n",
      "Computing for slp48...\n",
      "Computing for slp59...\n",
      "Computing for slp60...\n",
      "Computing for slp61...\n",
      "Computing for slp66...\n",
      "Computing for slp67x...\n"
     ]
    }
   ],
   "source": [
    "feature_sampen_resp = {}\n",
    "\n",
    "\n",
    "for key in data_keys:\n",
    "    print(\"Computing for \"+ key + \"...\")\n",
    "    resp_data = resp_data_set_epochs[key]\n",
    "\n",
    "    sampen_val = resp_data.resp.apply(lambda x: (nolds.sampen(x)))\n",
    "    feature_sampen_resp[key] = {'_feat' : list(sampen_val)}           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### AR and MA parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_sig = resp_data.resp.ix[0]\n",
    "sample_time = np.arange(len(sample_sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Required argument 'month' (pos 2) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-b12225e65e05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msample_timestamp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Required argument 'month' (pos 2) not found"
     ]
    }
   ],
   "source": [
    "sample_timestamp = np.zeros_like(sample_time)\n",
    "\n",
    "for i in sample_time:\n",
    "    sample_timestamp[i] = datetime.datetime(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "arma_mod30 = sm.tsa.ARMA(sample_sig, (3,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The computed initial AR coefficients are not stationary\nYou should induce stationarity, choose a different model order, or you can\npass your own start_params.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-50844ddef7c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marma_mod30\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/eventura/anaconda/lib/python2.7/site-packages/statsmodels/tsa/arima_model.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, trend, method, transparams, solver, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# estimate starting parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m             \u001b[0mstart_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_start_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_ar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransparams\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# transform initial parameters to ensure invertibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eventura/anaconda/lib/python2.7/site-packages/statsmodels/tsa/arima_model.pyc\u001b[0m in \u001b[0;36m_fit_start_params\u001b[0;34m(self, order, method)\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglike_css\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;31m#start_params = [.1]*(k_ar+k_ma+k_exog) # different one for k?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0mstart_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_start_params_hr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \u001b[0mstart_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invtransparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/eventura/anaconda/lib/python2.7/site-packages/statsmodels/tsa/arima_model.pyc\u001b[0m in \u001b[0;36m_fit_start_params_hr\u001b[0;34m(self, order)\u001b[0m\n\u001b[1;32m    533\u001b[0m         if p and not np.all(np.abs(np.roots(np.r_[1, -start_params[k:k + p]]\n\u001b[1;32m    534\u001b[0m                                             )) < 1):\n\u001b[0;32m--> 535\u001b[0;31m             raise ValueError(\"The computed initial AR coefficients are not \"\n\u001b[0m\u001b[1;32m    536\u001b[0m                              \u001b[0;34m\"stationary\\nYou should induce stationarity, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m                              \u001b[0;34m\"choose a different model order, or you can\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The computed initial AR coefficients are not stationary\nYou should induce stationarity, choose a different model order, or you can\npass your own start_params."
     ]
    }
   ],
   "source": [
    "arma_mod30.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unbound method fit() must be called with ARIMA instance as first argument (got ndarray instance instead)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-46bde1ca111d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0marma_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marima\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mARIMA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0marma_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unbound method fit() must be called with ARIMA instance as first argument (got ndarray instance instead)"
     ]
    }
   ],
   "source": [
    "arma_model = arima.ARIMA\n",
    "arma_model.fit(resp_data.resp.ix[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "### III. ECG signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Divide ECG data per 30-second epoch. \n",
    "\n",
    "ecg_data_set_epochs = {}\n",
    "\n",
    "for key in data_keys:\n",
    "    ecg_sig = ecg_data_set[key]\n",
    "    time_sig = np.arange(len(ecg_sig))/fs\n",
    "\n",
    "    # Divide into windows\n",
    "    ecg_windows = su.divide_to_epochs(ecg_sig, ann_index[key], win_dur, fs)\n",
    "    time_windows = su.divide_to_epochs(time_sig, ann_index[key], win_dur, fs)\n",
    "    \n",
    "    ecg_data_set_epochs[key] = pd.DataFrame({'ecg': list(ecg_windows), '_time': list(time_windows)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III.1 Heart rate\n",
    "*Reciprocal of the mean R-R interval in an epoch (unit: beats/minute)*\n",
    "\n",
    "\n",
    "#### III.2 Heart rate variability\n",
    "*Standard deviation of the R-R intervals in an epoch (unit: milliseconds)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_heart_rate = {}\n",
    "feature_heart_rate_var = {}\n",
    "\n",
    "for key in data_keys:\n",
    "    ecg_data = ecg_data_set_epochs[key]\n",
    "    \n",
    "    # Get time corresponding to R peaks\n",
    "    ecg_data['r_peaks'] = ecg_data.ecg.apply(lambda x: ecg.hamilton_segmenter(x, sampling_rate=250)['rpeaks'])\n",
    "    ecg_data['r_time'] = ecg_data.apply(lambda x: list(x._time[x.r_peaks]), axis = 1)\n",
    "    \n",
    "    # Compute heart rate\n",
    "    ecg_data['heart_rate'] = ecg_data.r_time.apply(lambda x: su.heart_rate(np.array(x))*60)\n",
    "    ecg_data['window_time'] = ecg_data['_time'].apply(lambda x: x[-1])\n",
    "        \n",
    "    # Compute heart rate variability\n",
    "    ecg_data['heart_rate_var'] = ecg_data.r_time.apply(lambda x: su.heart_rate_var(np.array(x))*1000)\n",
    "    \n",
    "    feature_heart_rate[key] = {'_feat' : ecg_data.heart_rate.values}\n",
    "    feature_heart_rate_var[key] = {'_feat' : ecg_data.heart_rate_var.values}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III.3 Histogram of ECG data\n",
    "Use the counts for each bin of the magnitude histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_hist_ecg = {}\n",
    "\n",
    "for key in data_keys: \n",
    "#     print(\"Computing for \"+ key + \"...\")\n",
    "    ecg_data = ecg_data_set_epochs[key]\n",
    "\n",
    "    hist_windows = ecg_data.ecg.apply(lambda x: np.histogram(x, bins=nbins, normed=True)[0])\n",
    "    feature_hist_ecg[key] = {'_feat' : (np.asarray(hist_windows))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III.4 Ratio of standard deviation and mean of magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_mean_vs_std_ecg = {}\n",
    "\n",
    "for key in data_keys:\n",
    "#     print(\"Computing for \"+ key + \"...\")\n",
    "    ecg_data = ecg_data_set_epochs[key]\n",
    "\n",
    "    mean_vs_std = ecg_data.ecg.apply(lambda x: (np.mean(x)/np.std(x)))\n",
    "    feature_mean_vs_std_ecg[key] = {'_feat' : list(mean_vs_std)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III.5 Ratio of  mean and standard deviation  of peak-to-peak duration of ecg signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for slp01a...\n",
      "Computing for slp01b...\n",
      "Computing for slp02a...\n",
      "Computing for slp02b...\n",
      "Computing for slp03...\n",
      "Computing for slp04...\n",
      "Computing for slp14...\n",
      "Computing for slp16...\n",
      "Computing for slp32...\n",
      "Computing for slp37...\n",
      "Computing for slp41...\n",
      "Computing for slp45...\n",
      "Computing for slp48...\n",
      "Computing for slp59...\n",
      "Computing for slp60...\n",
      "Computing for slp61...\n",
      "Computing for slp66...\n",
      "Computing for slp67x...\n"
     ]
    }
   ],
   "source": [
    "feature_mean_vs_std_p2p_dur_ecg = {}\n",
    "\n",
    "for key in data_keys:\n",
    "    print(\"Computing for \"+ key + \"...\")\n",
    "    ecg_data = ecg_data_set_epochs[key]\n",
    "\n",
    "    p2p_dur = ecg_data.ecg.apply(lambda x: su.bio_signal_peak_detect(x, fs, 'ecg'))\\\n",
    "                            .apply(lambda x: np.array(x[0][1:]) - np.array(x[0][:-1]))\n",
    "    mean_vs_std = p2p_dur.apply(lambda x: np.nanmean(x)/np.nanstd(x))\n",
    "    feature_mean_vs_std_p2p_dur_ecg[key] = {'_feat' : list(mean_vs_std)}           \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III.6 Ratio of mean and standard deviation of amplitude\n",
    "#### III.7 Ratio of max and mean of magnitude of amplitude\n",
    "#### III.8 Ratio of min and mean of magnitude of amplitude\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for slp01a...\n",
      "Computing for slp01b...\n",
      "Computing for slp02a...\n",
      "Computing for slp02b...\n",
      "Computing for slp03...\n",
      "Computing for slp04...\n",
      "Computing for slp14...\n",
      "Computing for slp16...\n",
      "Computing for slp32...\n",
      "Computing for slp37...\n",
      "Computing for slp41...\n",
      "Computing for slp45...\n",
      "Computing for slp48...\n",
      "Computing for slp59...\n",
      "Computing for slp60...\n",
      "Computing for slp61...\n",
      "Computing for slp66...\n",
      "Computing for slp67x...\n"
     ]
    }
   ],
   "source": [
    "feature_mean_vs_std_amp_ecg = {}\n",
    "feature_max_vs_mean_amp_ecg = {}\n",
    "feature_min_vs_mean_amp_ecg = {}\n",
    "\n",
    "for key in data_keys:\n",
    "    print(\"Computing for \"+ key + \"...\")\n",
    "    ecg_data = ecg_data_set_epochs[key]\n",
    "\n",
    "    amplitude = ecg_data.ecg.apply(lambda x: su.compute_amplitude(x, fs, 'ecg'))\n",
    "    mean_vs_std = amplitude.apply(lambda x: np.nanmean(x)/np.nanstd(x))\n",
    "    feature_mean_vs_std_amp_ecg[key] = {'_feat' : list(mean_vs_std)}           \n",
    "    \n",
    "    max_vs_mean = amplitude.apply(lambda x: np.nanmax(x)/np.nanmean(x))\n",
    "    feature_max_vs_mean_amp_ecg[key] = {'_feat' : list(max_vs_mean)}           \n",
    "    \n",
    "    min_vs_mean = amplitude.apply(lambda x: np.nanmax(x)/np.nanmean(x))\n",
    "    feature_min_vs_mean_amp_ecg[key] = {'_feat' : list(min_vs_mean)}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Blood Pressure signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divide ECG data per 30-second epoch. \n",
    "\n",
    "bp_data_set_epochs = {}\n",
    "\n",
    "for key in data_keys:\n",
    "    bp_sig = bp_data_set[key]\n",
    "    time_sig = np.arange(len(bp_sig))/fs\n",
    "\n",
    "    # Divide into windows\n",
    "    bp_windows = su.divide_to_epochs(bp_sig, ann_index[key], win_dur, fs)\n",
    "    time_windows = su.divide_to_epochs(time_sig, ann_index[key], win_dur, fs)\n",
    "    \n",
    "    bp_data_set_epochs[key] = pd.DataFrame({'bp': list(bp_windows), '_time': list(time_windows)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV.1 Histogram of BP data\n",
    "Use the counts for each bin of the magnitude histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_hist_bp = {}\n",
    "\n",
    "for key in data_keys:\n",
    "#     print(\"Computing for \"+ key + \"...\")\n",
    "    bp_data = bp_data_set_epochs[key]\n",
    "\n",
    "    hist_windows = bp_data.bp.apply(lambda x: np.histogram(x, bins=nbins, normed=True)[0])\n",
    "    feature_hist_bp[key] = {'_feat' : (np.asarray(hist_windows))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV.2 Ratio of standard deviation and mean of magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_mean_vs_std_bp = {}\n",
    "\n",
    "for key in data_keys:\n",
    "#     print(\"Computing for \"+ key + \"...\")\n",
    "    bp_data = bp_data_set_epochs[key]\n",
    "\n",
    "    mean_vs_std = bp_data.bp.apply(lambda x: (np.mean(x)/np.std(x)))\n",
    "    feature_mean_vs_std_bp[key] = {'_feat' : list(mean_vs_std)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #raw value\n",
    "# feature_raw_bp = {}\n",
    "\n",
    "# for key in data_keys:\n",
    "# #     print(\"Computing for \"+ key + \"...\")\n",
    "#     bp_data = bp_data_set_epochs[key]\n",
    "\n",
    "#     raw_val = bp_data.bp.apply(lambda x: x[-1])\n",
    "#     feature_raw_bp[key] = {'_feat' : list(raw_val)}"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
